{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Datium Part_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uc4ZhBw_bm_c",
        "outputId": "8315c7a2-e75b-4e53-9d37-bc5d5914e9d8"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install mlflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVbCfqC5s4Vk",
        "outputId": "d771532f-caff-44cc-cc81-e2f4c32db3f9"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.7/dist-packages (1.25.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.3.5)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (4.11.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.21.6)\n",
            "Requirement already satisfied: databricks-cli>=0.8.7 in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.16.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from mlflow) (6.0)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.4.2)\n",
            "Requirement already satisfied: requests>=2.17.3 in /usr/local/lib/python3.7/dist-packages (from mlflow) (2.23.0)\n",
            "Requirement already satisfied: gitpython>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (3.1.27)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (7.1.2)\n",
            "Requirement already satisfied: gunicorn in /usr/local/lib/python3.7/dist-packages (from mlflow) (20.1.0)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.7.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mlflow) (21.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from mlflow) (2022.1)\n",
            "Requirement already satisfied: querystring-parser in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.2.4)\n",
            "Requirement already satisfied: protobuf>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (3.17.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.4.1)\n",
            "Requirement already satisfied: docker>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (5.0.3)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.1.4)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.4)\n",
            "Requirement already satisfied: prometheus-flask-exporter in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.20.1)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.4.36)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow) (3.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow) (1.15.0)\n",
            "Requirement already satisfied: pyjwt>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow) (2.3.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow) (0.8.9)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from docker>=4.0.0->mlflow) (1.3.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython>=2.1.0->mlflow) (4.0.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from gitpython>=2.1.0->mlflow) (4.2.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow) (5.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata!=4.7.0,>=3.7.0->mlflow) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (2021.10.8)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->mlflow) (5.7.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->mlflow) (1.2.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow) (1.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask->mlflow) (2.0.1)\n",
            "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.7/dist-packages (from gunicorn->mlflow) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mlflow) (3.0.8)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->mlflow) (2.8.2)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from prometheus-flask-exporter->mlflow) (0.14.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GA5dQdn4amjs"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import warnings\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from urllib.parse import urlparse\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import xgboost as xgb\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.pipeline import Pipeline\n"
      ],
      "metadata": {
        "id": "IltU788Um2zK"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = mlflow.tracking.MlflowClient()\n",
        "\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.WARN)\n",
        "logger = logging.getLogger(__name__)\n"
      ],
      "metadata": {
        "id": "kr_9oHjxm7Jv"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "kj_XUGilawha"
      },
      "outputs": [],
      "source": [
        "def eval_metrics(actual, pred):\n",
        "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
        "    mae = mean_absolute_error(actual, pred)\n",
        "    r2 = r2_score(actual, pred)\n",
        "    return rmse, mae, r2\n",
        "\n",
        "  \n",
        "    \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_data(data_path):\n",
        "   # Read the wine-quality csv file from the URL\n",
        "    data = pd.read_csv(data_path, low_memory=False,encoding='latin-1', na_values=['(NA)']).fillna(0)\n",
        "    for column in data.columns:\n",
        "         data[column] = pd.Categorical(data[column]).codes\n",
        "      # Split the data into training and test sets. (0.75, 0.25) split.\n",
        "    train, test = train_test_split(data)\n",
        "    train_x = train.drop([\"Sold_Amount\"], axis=1)\n",
        "    test_x = test.drop([\"Sold_Amount\"], axis=1)\n",
        "    train_y = train[[\"Sold_Amount\"]]\n",
        "    test_y = test[[\"Sold_Amount\"]]\n",
        "    return train_x, test_x, train_y, test_y \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Tp5FQIoRnFek"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, test_x, train_y, test_y = build_data(r'/gdrive/My Drive/Colab Notebooks/datium_train.csv')\n",
        "\n",
        "def xgb_model(training_data, test_data,  max_depth, ntrees, lr):\n",
        "    \n",
        "    with mlflow.start_run():\n",
        "        xgbRegressor = xgb.XGBRegressor(\n",
        "        max_depth=max_depth,\n",
        "        n_estimators=ntrees,\n",
        "        learning_rate=lr,\n",
        "        random_state=42,\n",
        "        seed=42,\n",
        "        subsample=0.75,\n",
        "        colsample_bytree=0.75,\n",
        "        reg_lambda=1,\n",
        "        gamma=1,\n",
        "        objective = \"reg:squarederror\"\n",
        "\n",
        ")\n",
        "        #pipeline = Pipeline(steps=[(\"regressor\", xgbRegressor)])\n",
        "\n",
        "\n",
        "        xgbRegressor.fit(train_x, train_y)\n",
        "        #,early_stopping_rounds=20,eval_set=[(test_x, test_y)])\n",
        "\n",
        "        predicted_qualities = xgbRegressor.predict(test_x)\n",
        "\n",
        "        (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n",
        "\n",
        "        print('rmse\":',rmse)\n",
        "        print('r2',r2)\n",
        "        print('mae',mae)\n",
        "        mlflow.log_metric(\"rmse\", rmse)\n",
        "        mlflow.log_metric(\"r2\", r2)\n",
        "        mlflow.log_metric(\"mae\", mae)\n",
        "\n",
        "        mlflow.sklearn.log_model(xgbRegressor, \"model\") \n",
        "        feature_importances = pd.DataFrame(xgbRegressor.feature_importances_, index=train_x.columns.tolist(), columns=['importance'])\n",
        "        feature_importances.sort_values('importance', ascending=False)\n",
        "  \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    xgb_model(train_y,test_y, 3,130,0.3)"
      ],
      "metadata": {
        "id": "ejqqbcENnR6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "701452f3-6d7f-445b-f9f5-9109b1e8772a"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rmse\": 211.17184\n",
            "r2 0.8980106649592777\n",
            "mae 146.9664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction\n"
      ],
      "metadata": {
        "id": "XKSX8-hjrQ4j"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, test_x, train_y, test_y = build_data(r'/gdrive/My Drive/Colab Notebooks/datium_test.csv')\n"
      ],
      "metadata": {
        "id": "XY4505Dafwg4"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model(train_y,test_y, 3,130,0.3)"
      ],
      "metadata": {
        "id": "vtcSHJSpnawa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15ec8598-33f1-4cc3-9f41-6320bec3acd4"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rmse\": 122.22432\n",
            "r2 0.9464962281214215\n",
            "mae 89.237976\n"
          ]
        }
      ]
    }
  ]
}